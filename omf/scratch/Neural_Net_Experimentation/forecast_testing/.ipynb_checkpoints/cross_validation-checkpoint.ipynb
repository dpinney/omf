{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from scipy.stats.mstats import zscore\n",
    "import time\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('holidays.pickle', 'rb') as f:\n",
    "    nerc6 = pickle.load(f)\n",
    "\n",
    "def isHoliday(holiday, df):\n",
    "    # New years, memorial, independence, labor day, Thanksgiving, Christmas\n",
    "    m1 = None\n",
    "    if holiday == \"New Year's Day\":\n",
    "        m1 = (df[\"dates\"].dt.month == 1) & (df[\"dates\"].dt.day == 1)\n",
    "    if holiday == \"Independence Day\":\n",
    "        m1 = (df[\"dates\"].dt.month == 7) & (df[\"dates\"].dt.day == 4)\n",
    "    if holiday == \"Christmas Day\":\n",
    "        m1 = (df[\"dates\"].dt.month == 12) & (df[\"dates\"].dt.day == 25)\n",
    "    m1 = df[\"dates\"].dt.date.isin(nerc6[holiday]) if m1 is None else m1\n",
    "    m2 = df[\"dates\"].dt.date.isin(nerc6.get(holiday + \" (Observed)\", []))\n",
    "    return m1 | m2\n",
    "\n",
    "def makeUsefulDf(df):\n",
    "    \"\"\"\n",
    "    Turn a dataframe of datetime and load data into a dataframe useful for\n",
    "    machine learning. Normalize values and turn \n",
    "    Features are placed into r_df (return dataframe), creates the following columns\n",
    "\n",
    "        YEARS SINCE 2000\n",
    "\n",
    "        LOAD AT THIS TIME DAY BEFORE\n",
    "\n",
    "        HOUR OF DAY\n",
    "        - is12AM (0, 1)\n",
    "        - is1AM (0, 1)\n",
    "        ...\n",
    "        - is11PM (0, 1)\n",
    "\n",
    "        DAYS OF THE WEEK\n",
    "        - isSunday (0, 1)\n",
    "        - isMonday (0, 1)\n",
    "        ...\n",
    "        - isSaturday (0, 1)\n",
    "\n",
    "        MONTHS OF THE YEAR\n",
    "        - isJanuary (0, 1)\n",
    "        - isFebruary (0, 1)\n",
    "        ...\n",
    "        - isDecember (0, 1)\n",
    "\n",
    "        TEMPERATURE\n",
    "        - Celcius (normalized from -1 to 1)\n",
    "\n",
    "        PREVIOUS DAY'S LOAD \n",
    "        - 12AM of day previous (normalized from -1 to 1)\n",
    "        - 1AM of day previous (normalized from -1 to 1)\n",
    "        ...\n",
    "        - 11PM of day previous (normalized from -1 to 1)\n",
    "\n",
    "        HOLIDAYS (the nerc6 holidays)\n",
    "        - isNewYears (0, 1)\n",
    "        - isMemorialDay (0, 1)\n",
    "        ...\n",
    "        - is Christmas (0, 1)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def _normalizeCol(l):\n",
    "        #s = l.max() - l.min()\n",
    "        #return l if s == 0 else (l - l.mean()) / l.std()\n",
    "        return zscore(l)\n",
    "    def _chunks(l, n):\n",
    "        return [l[i : i + n] for i in range(0, len(l), n)]\n",
    "\n",
    "    r_df = pd.DataFrame()\n",
    "    r_df[\"load_n\"] = _normalizeCol(df[\"load\"])\n",
    "    r_df[\"years_n\"] = _normalizeCol(df[\"dates\"].dt.year - 2000)\n",
    "\n",
    "    # fix outliers\n",
    "    m = df[\"tempc\"].replace([-9999], np.nan)\n",
    "    m.ffill(inplace=True)\n",
    "    # 2.5 degrees average std error for the national weather service\n",
    "    temp_noise = m\n",
    "    r_df[\"temp_n\"] = _normalizeCol(temp_noise)\n",
    "    r_df['temp_n^2'] = r_df[\"temp_n\"]**2\n",
    "\n",
    "    # add the value of the load 24hrs before\n",
    "    r_df[\"load_prev_n\"] = r_df[\"load_n\"].shift(24)\n",
    "    r_df[\"load_prev_n\"].bfill(inplace=True)\n",
    "\n",
    "    # create day of week vector\n",
    "    r_df[\"day\"] = df[\"dates\"].dt.dayofweek  # 0 is Monday.\n",
    "    w = [\"S\", \"M\", \"T\", \"W\", \"R\", \"F\", \"A\"]\n",
    "    for i, d in enumerate(w):\n",
    "        r_df[d] = (r_df[\"day\"] == i).astype(int)\n",
    "\n",
    "        # create hour of day vector\n",
    "    r_df[\"hour\"] = df[\"dates\"].dt.hour\n",
    "    d = [(\"h\" + str(i)) for i in range(24)]\n",
    "    for i, h in enumerate(d):\n",
    "        r_df[h] = (r_df[\"hour\"] == i).astype(int)\n",
    "\n",
    "        # create month vector\n",
    "    r_df[\"month\"] = df[\"dates\"].dt.month\n",
    "    y = [(\"m\" + str(i)) for i in range(12)]\n",
    "    for i, m in enumerate(y):\n",
    "        r_df[m] = (r_df[\"month\"] == i).astype(int)\n",
    "\n",
    "        # create 'load day before' vector\n",
    "    n = np.array([val for val in _chunks(list(r_df[\"load_n\"]), 24) for _ in range(24)])\n",
    "    l = [\"l\" + str(i) for i in range(24)]\n",
    "    for i, s in enumerate(l):\n",
    "        r_df[s] = n[:, i]\n",
    "\n",
    "        # create holiday booleans\n",
    "    r_df[\"isNewYears\"] = isHoliday(\"New Year's Day\", df)\n",
    "    r_df[\"isMemorialDay\"] = isHoliday(\"Memorial Day\", df)\n",
    "    r_df[\"isIndependenceDay\"] = isHoliday(\"Independence Day\", df)\n",
    "    r_df[\"isLaborDay\"] = isHoliday(\"Labor Day\", df)\n",
    "    r_df[\"isThanksgiving\"] = isHoliday(\"Thanksgiving\", df)\n",
    "    r_df[\"isChristmas\"] = isHoliday(\"Christmas Day\", df)\n",
    "\n",
    "    m = r_df.drop([\"month\", \"hour\", \"day\", \"load_n\"], axis=1)\n",
    "    return m\n",
    "\n",
    "def neural_net_predictions(all_X, all_y):\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras import layers\n",
    "    tic = time.time()\n",
    "    X_train, y_train = all_X[:-8760], all_y[:-8760]\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Dense(all_X.shape[1], activation=tf.nn.relu, input_shape=[len(X_train.keys())]),\n",
    "        layers.Dense(all_X.shape[1], activation=tf.nn.relu),\n",
    "        layers.Dense(all_X.shape[1], activation=tf.nn.relu),\n",
    "        layers.Dense(all_X.shape[1], activation=tf.nn.relu),\n",
    "        layers.Dense(all_X.shape[1], activation=tf.nn.relu),\n",
    "        layers.Dense(1)\n",
    "      ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"mean_squared_error\",\n",
    "        optimizer=optimizer,\n",
    "        metrics=[\"mean_absolute_error\", \"mean_squared_error\"],\n",
    "    )\n",
    "\n",
    "    EPOCHS = 100\n",
    "\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        epochs=EPOCHS,\n",
    "        validation_split=0.2,\n",
    "        verbose=0,\n",
    "        callbacks=[early_stop],\n",
    "    )\n",
    "    \n",
    "    def MAPE(predictions, answers):\n",
    "        # THIS IS PROBLEMATIC IF Y is EVER 0\n",
    "        assert len(predictions) == len(answers)\n",
    "        return sum([abs(x-y)/(y+1e-5) for x, y in zip(predictions, answers)])/len(answers)*100   \n",
    "    \n",
    "    predictions = [float(f) for f in model.predict(all_X[-8760:])]\n",
    "    train = [float(f) for f in model.predict(all_X[:-8760])]\n",
    "    accuracy = {\n",
    "        'test': MAPE(predictions, all_y[-8760:]),\n",
    "        'train': MAPE(train, all_y[:-8760])\n",
    "    }\n",
    "    \n",
    "    return predictions, accuracy, time.time() - tic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCENT.csv {'test': 1.681302700166577, 'train': 1.7087428784470091} 269.84409403800964\n",
      "NCENT.csv {'test': 0.8791314198772925, 'train': 0.7945583441610236} 297.8987672328949\n",
      "COAST.csv {'test': 1.5552924629527987, 'train': 1.7896520071636384} 224.67304968833923\n",
      "FWEST.csv {'test': 2.514862726510828, 'train': 1.2584149693165272} 253.5422010421753\n",
      "EAST.csv {'test': 0.9309198841164392, 'train': 0.8214532386860942} 374.4927089214325\n",
      "SOUTH.csv {'test': 2.245935020968539, 'train': 2.075756950161136} 193.11839532852173\n",
      "NORTH.csv {'test': 0.8792736540018945, 'train': 0.8475251789404536} 426.1031939983368\n"
     ]
    }
   ],
   "source": [
    "for f in os.listdir('data/test'):\n",
    "    if f.endswith('.csv'):\n",
    "        df = pd.read_csv('data/test/' + f, parse_dates=['dates'])\n",
    "        all_X = makeUsefulDf(df)\n",
    "        all_y = df['load']\n",
    "        predictions, accuracy, t = neural_net_predictions(all_X, all_y)\n",
    "        print(f, accuracy, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
